# Setup and run docker containers for still image inference on camera using TPU
#
# Running example
#   $ docker-compose -H tcp://172.25.75.141:2375 -f camera-image.yml up

version: '2.0'
services:
  inference-client:
    image: axisecp/inference-client:1.0.0-armv7hf
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100k"
    depends_on:
      - inference-server
      - ssdlite_mobilenet_object
    environment:
      - INFERENCE_HOST=inference-server
      - INFERENCE_PORT=8501
      - LD_LIBRARY_PATH=/host/lib
      - MODEL_NAME=ssdlite-mobilenet-v2-tpu
      - MODEL_INPUT_SIZE=300x300
      - OBJECT_LIST_PATH=/model/objects.txt
      - IMAGE_PATH=dog416.png
      - DEBUG=y
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /lib:/host/lib
      - ssdlite_mobilenet_object:/model:ro
      - /tmp:/output
      - /var/run/dbus/system_bus_socket:/var/run/dbus/system_bus_socket
      - /var/run/statuscache:/var/run/statuscache
    devices:
      - /dev/datacache0:/dev/datacache0:rw

  inference-server:
    image: axisecp/larod-inference-server:2.0.0-armv7hf
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100k"
    command: /usr/bin/larod-inference-server -v -p 8501 -j 1 -m /model/ssdlite-mobilenet-v2-tpu
    depends_on:
      - ssdlite_mobilenet_object
    expose:
      - 8501
    volumes:
      - ssdlite_mobilenet_object:/model:ro
      - /run/dbus/system_bus_socket:/run/dbus/system_bus_socket
      - /tmp:/tmp

  ssdlite_mobilenet_object:
    image: axisecp/acap-dl-models:ssdlite-mobilenet-v2
    restart: 'no'
    volumes:
      - ssdlite_mobilenet_object:/model

volumes:
  ssdlite_mobilenet_object: {}